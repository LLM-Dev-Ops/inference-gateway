# Kustomize configuration for LLM Inference Gateway
# Use: kubectl apply -k deploy/kubernetes/

apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization

metadata:
  name: llm-inference-gateway

# Namespace for all resources
namespace: llm-gateway

# Common labels applied to all resources
commonLabels:
  app.kubernetes.io/name: llm-inference-gateway
  app.kubernetes.io/part-of: llm-platform
  app.kubernetes.io/managed-by: kustomize

# Common annotations
commonAnnotations:
  app.kubernetes.io/version: "0.1.0"

# Resources to include
resources:
  - namespace.yaml
  - configmap.yaml
  - secret.yaml
  - rbac.yaml
  - deployment.yaml
  - service.yaml
  - hpa.yaml
  - ingress.yaml
  # Uncomment to include Redis
  # - redis.yaml

# ConfigMap generator (alternative to static configmap.yaml)
# configMapGenerator:
#   - name: llm-gateway-config
#     files:
#       - gateway.yaml=configs/gateway.yaml

# Secret generator (for development only - use external secrets in production)
# secretGenerator:
#   - name: llm-gateway-secrets
#     envs:
#       - .env.secret

# Image customization
images:
  - name: llm-inference-gateway
    newName: llm-inference-gateway
    newTag: latest

# Patches for environment-specific customization
# patches:
#   - path: patches/deployment-resources.yaml
#   - path: patches/hpa-scaling.yaml

# Replicas override
# replicas:
#   - name: llm-gateway
#     count: 5

