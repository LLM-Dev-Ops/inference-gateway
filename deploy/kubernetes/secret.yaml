# LLM Inference Gateway Secrets
# Contains sensitive configuration - REPLACE values before deploying!
#
# IMPORTANT: This file contains placeholder values.
# In production, use:
# - Kubernetes Secrets with external secrets management (Vault, AWS Secrets Manager, etc.)
# - Sealed Secrets
# - SOPS encrypted secrets
# - External Secrets Operator
#
# NEVER commit actual secrets to version control!

apiVersion: v1
kind: Secret
metadata:
  name: llm-gateway-secrets
  namespace: llm-gateway
  labels:
    app.kubernetes.io/name: llm-inference-gateway
    app.kubernetes.io/component: secrets
type: Opaque
stringData:
  # Provider API Keys - REPLACE THESE
  OPENAI_API_KEY: "sk-your-openai-key-here"
  ANTHROPIC_API_KEY: "sk-ant-your-anthropic-key-here"
  GOOGLE_API_KEY: "your-google-api-key-here"

  # Redis password (if using Redis)
  REDIS_PASSWORD: ""

  # JWT secret for authentication (if using JWT)
  JWT_SECRET: "your-jwt-secret-at-least-32-characters-long"

  # API keys for gateway authentication
  # Format: key_id:hashed_key:tenant_id
  API_KEYS: |
    []

---
# External Secrets example (for use with External Secrets Operator)
# Uncomment and configure if using ESO
#
# apiVersion: external-secrets.io/v1beta1
# kind: ExternalSecret
# metadata:
#   name: llm-gateway-external-secrets
#   namespace: llm-gateway
# spec:
#   refreshInterval: "1h"
#   secretStoreRef:
#     kind: ClusterSecretStore
#     name: vault-backend  # or aws-secrets-manager, gcp-secret-manager, etc.
#   target:
#     name: llm-gateway-secrets
#     creationPolicy: Owner
#   data:
#     - secretKey: OPENAI_API_KEY
#       remoteRef:
#         key: llm-gateway/openai
#         property: api_key
#     - secretKey: ANTHROPIC_API_KEY
#       remoteRef:
#         key: llm-gateway/anthropic
#         property: api_key
